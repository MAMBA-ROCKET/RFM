import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
import sympy as sp

#device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

torch.set_default_dtype(torch.float64)

torch.manual_seed(42)
np.random.seed(42)

# Consider a 2D Poisson equation on the unit square with Dirichlet boundary conditions

num_points_i = 3
# 在 [0, 1] 之间生成 num_points_i 个点
x = torch.linspace(0, 1, num_points_i+2)[1:-1].requires_grad_()
y = torch.linspace(0, 1, num_points_i+2)[1:-1].requires_grad_()


# 使用 torch.meshgrid 生成 x 和 y 的坐标s网格
X, Y = torch.meshgrid(x, y)

# 将 X 和 Y 从 2D 转为 1D
x_points = X.flatten()
y_points = Y.flatten()

num_points_i = num_points_i**2


num_points_b = 3

# 在每个边界上生成 num_points_b 个点
x_boundary_points = torch.cat((torch.zeros(num_points_b), torch.ones(num_points_b), torch.linspace(0, 1, num_points_b+2)[1:-1],torch.linspace(0, 1, num_points_b+2)[1:-1]))
y_boundary_points = torch.cat((torch.linspace(0, 1, num_points_b+2)[1:-1], torch.linspace(0, 1, num_points_b+2)[1:-1], torch.zeros(num_points_b), torch.ones(num_points_b)))
boundary_points = (x_boundary_points.requires_grad_(), y_boundary_points.requires_grad_())


x_total = torch.cat((x_points, x_boundary_points))
y_total = torch.cat((y_points, y_boundary_points))

num_points = num_points_i + 4*num_points_b

# Code above describes where the local solutions are constrcutred.
# The number of points is M_p

# When building the loss function, where the error is computed, we need to have a different set of points to evaluate, i.e., the collocation points.
# the number of collocation points is C_I and C_B
# the number of loss is N = K_I*C_I + K_B*C_B, K_I and K_B are the number of constraints on the interior and boundary respectively.


class ExtendedLocalFeatureModelWithWeights(nn.Module):
    def __init__(self, num_features, num_points, M):
        super(ExtendedLocalFeatureModelWithWeights, self).__init__()
        #self.linear = nn.Linear(num_features+M, 1, bias=False)
        self.local_weights = nn.Parameter(torch.randn(num_points, num_features)) 
        self.global_weights = nn.Parameter(torch.randn(M, 1))  
        self.M = M
        self.J_n = num_features
        
        # for local features
        self.w = nn.Parameter(torch.randn(num_features, 1)) 
        self.b = nn.Parameter(torch.randn(num_features, 1))  # current structure of basis functions don't need b
        self.w.requires_grad = False
        self.b.requires_grad = False


        # for global features
        self.w1 = nn.Parameter(torch.randn(M, 1))  
        self.w2 = nn.Parameter(torch.randn(M, 1))  
        self.w1.requires_grad = False
        self.w2.requires_grad = False

        local_features_list = [torch.sin(self.w[i] * (x)) * torch.sin(self.w[i] * (y)) for i in range(self.J_n)]
        self.local_features = torch.stack(local_features_list, dim=1)
        global_features_list = [torch.sin(self.w1[i] * torch.pi * (x)) * torch.sin(self.w2[i] * torch.pi * (y)) for i in range(self.M)]
        self.global_features = torch.stack(global_features_list, dim=1)

        
    def forward(self, x, y, point_idx=None):    

        u = torch.zeros_like(x).unsqueeze(0).unsqueeze(1)


        if point_idx is not None:
            for i in range(num_features):
                u += self.local_weights[point_idx,i]*self.local_features[0,i]
        else:
            for i in range(self.M):
                weight = self.global_weights[i,0].view(-1,1) #ok
                feature = self.global_features[0,i].view(-1,1)
                u += weight * feature

        return u
        



def psi(x):
    psi = torch.zeros_like(x)
    cond1 = (-5/4 <= x) & (x < -3/4)
    cond2 = (-3/4 <= x) & (x < 3/4)
    cond3 = (3/4 <= x) & (x < 5/4)
    psi[cond1] = (1 + torch.sin(2 * torch.pi * x[cond1])) / 2
    psi[cond2] = 1
    psi[cond3] = (1 - torch.sin(2 * torch.pi * x[cond3])) / 2
    return psi

def unity_function(x, y, center_x, center_y, radius):
    x_hat = (x - center_x) / radius
    y_hat = (y - center_y) / radius
    return psi(x_hat)*psi(y_hat)


# Number of features locally
num_features = 20  

# Number of features globally
M = 10

# Network
net = ExtendedLocalFeatureModelWithWeights(num_features, num_points, M)

#net = net.to(device)

# Optimizer
#optimizer = optim.SGD(net.parameters(), lr=0.01)




class GradientDescentLineSearch:
    def __init__(self, parameters, alpha=0.5, beta=0.8, init_lr=1.0):
        self.parameters = list(parameters)
        self.alpha = alpha
        self.beta = beta
        self.init_lr = init_lr

    def step(self, compute_loss, x_points_test, y_points_test, u_global_test, co_global_test):

        # 获取当前损失值
        loss = compute_loss(x_points_test, y_points_test, u_global_test, co_global_test)
        print('current loss:',loss)
        # 计算梯度
        loss.backward(retain_graph=True)


# At least for now, parameters make sense.
        with torch.no_grad():            
            for param in self.parameters:
                if param.grad is not None:

                    direction = -param.grad  # 负梯度方向
                    print('direction:',direction)

                    # 线搜索
                    t = self.init_lr
                    

                    while compute_loss(x_points_test, y_points_test, u_global_test, co_global_test) > loss + self.alpha * t * torch.dot(param.grad.view(-1), direction.view(-1)):
                        print('loss_fn:',compute_loss(x_points_test, y_points_test, u_global_test, co_global_test))
                        print('loss:',loss)
                        print('descent',self.alpha * t * torch.dot(param.grad.view(-1), direction.view(-1)))
                        t *= self.beta

                        # Update the parameter
                        param.add_(direction, alpha=t)
                    
                    # Zero out the gradients for the next iteration
                    param.grad.zero_()



optimizer = GradientDescentLineSearch(net.parameters())



# Radius of local solutions
radius = 1/(np.sqrt(num_points_i)+1)  # let radius be based on the distance between two adjacent points
print(radius)



def global_solution(x, y, net, radius):

    global_sol = torch.zeros(1,1)

    global_sol += net(x, y)  #这是新的全局随机特征函数的贡献


    for idx in range(num_points_i):
        weight = unity_function(x, y, x_points[idx], y_points[idx], radius).view(-1,1)
        local_solution = net(x, y, idx)
        global_sol += weight * local_solution

    for idx in range(4*num_points_b):
        weight = unity_function(x, y, x_boundary_points[idx], y_boundary_points[idx], radius).view(-1,1)
        local_solution = net(x, y, idx + num_points_i)
        global_sol += weight * local_solution

    return global_sol # tensor.size([1,1])




def rescale_PDE(x,y,net,radius,x_total,y_total):
    co_w = torch.randn(num_features, 1)
    A = torch.zeros(num_points, num_features)  # 1<=n<=M_p 1<=j'<=J_n
    for n in range(num_points):
        for j in range(num_features):
            A[n,j] = unity_function(x,y,x_total[n],y_total[n],radius) * torch.sin(co_w[j] * (x)) * torch.sin(co_w[j] * (y))

    A_x = torch.autograd.grad(A.sum(), x, create_graph=True)[0]
    A_y = torch.autograd.grad(A.sum(), y, create_graph=True)[0]
    A_xx = torch.autograd.grad(A_x.sum(), x, create_graph=True)[0]
    A_yy = torch.autograd.grad(A_y.sum(), y, create_graph=True)[0]
    
    co = torch.max(torch.abs(A_xx+A_yy))

    return co

def rescale_boundary(x,y,net,radius,x_total,y_total):
    co_w = torch.randn(num_features, 1)
    A = torch.zeros(num_points, num_features)  # 1<=n<=M_p 1<=j'<=J_n
    for n in range(num_points):
        for j in range(num_features):
            A[n,j] = unity_function(x,y,x_total[n],y_total[n],radius) * torch.sin(co_w[j] * (x)) * torch.sin(co_w[j] * (y))
    
    co = torch.max(torch.abs(A-1))

    return co




def pde_loss_function(x, y, u, co):
    u_x = torch.autograd.grad(u.sum(), x, create_graph=True)[0]
    u_y = torch.autograd.grad(u.sum(), y, create_graph=True)[0]
    u_xx = torch.autograd.grad(u_x.sum(), x, create_graph=True)[0]
    u_yy = torch.autograd.grad(u_y.sum(), y, create_graph=True)[0]

    
    f = 2 * torch.pi**2 * torch.sin(torch.pi * x) * torch.sin(torch.pi * y)
    #print((u_xx + u_yy - f) ** 2)

    pde_loss = torch.sum((u_xx + u_yy - f) ** 2/co)
    return pde_loss


def boundary_loss_function(x, y, u, co):
    boundary_loss = torch.sum((u-1)**2/co)
    return boundary_loss


def compute_loss(x, y, u, co):
    return pde_loss_function(x, y, u, co[0:num_points_i_test,0]) + boundary_loss_function(x, y, u, co[num_points_i_test:num_points_test,0])


def final_solution(x_test,y_test,net,radius,n_points):
    final_sol = torch.zeros(n_points,n_points) # 2D

    for a in range(n_points):
        for b in range(n_points):
            final_sol[a,b] += global_solution(x_test[a,0], y_test[b,0], net, radius).squeeze()  # 0D

    return final_sol


# collocation points
num_points_i_test = 3

x_test_np = np.linspace(0, 1, num_points_i_test+2)[1:-1]
y_test_np = np.linspace(0, 1, num_points_i_test+2)[1:-1]
X_test_np, Y_test_np = np.meshgrid(x_test_np, y_test_np)


x_test = torch.linspace(0, 1, num_points_i_test+2)[1:-1].requires_grad_()
y_test = torch.linspace(0, 1, num_points_i_test+2)[1:-1].requires_grad_()

X_test, Y_test = torch.meshgrid(x_test, y_test)
x_points_test = X_test.flatten()
y_points_test = Y_test.flatten()

x_test  = x_test.view(-1, 1)
y_test  = y_test.view(-1, 1)

num_points_i_test = num_points_i_test**2

num_points_b_test = 3

x_boundary_points_test = torch.cat((torch.zeros(num_points_b_test), torch.ones(num_points_b_test), torch.linspace(0, 1, num_points_b_test+2)[1:-1],torch.linspace(0, 1, num_points_b_test+2)[1:-1])).requires_grad_()
y_boundary_points_test = torch.cat((torch.linspace(0, 1, num_points_b_test+2)[1:-1], torch.linspace(0, 1, num_points_b_test+2)[1:-1], torch.zeros(num_points_b_test), torch.ones(num_points_b_test))).requires_grad_()
boundary_points_test = (x_boundary_points_test.requires_grad_(), y_boundary_points_test.requires_grad_())

num_points_test = num_points_i_test + 4*num_points_b_test 


U_analytic = -np.sin(np.pi*X_test_np)*np.sin(np.pi*Y_test_np) + 1



# rescaling factor
co_global_test = torch.zeros(num_points_test,1)
for idx in range(num_points_i_test):
    co_global_test[idx,0] = rescale_PDE(x_points_test[idx], y_points_test[idx], net, radius,x_total,y_total)

for isx in range(4*num_points_b_test):
    co_global_test[isx + num_points_i_test,0] = rescale_boundary(x_boundary_points_test[isx], y_boundary_points_test[isx], net, radius,x_total,y_total)


print('co_global_test:',co_global_test)



flag = 1
epoch = 0
record_loss = np.array([0])
# Training
while flag == 1:
    print('epoch:',epoch)

    # for param in net.parameters():
    #     if param.grad is not None:
    #         param.grad.data.zero_()

    
    u_global_test = torch.zeros(num_points_test,1)
    for idx in range(num_points_i_test):
        u_global_test[idx,0] = global_solution(x_points_test[idx], y_points_test[idx], net, radius)

    for isx in range(4*num_points_b_test):
        u_global_test[isx + num_points_i_test,0] = global_solution(x_boundary_points_test[isx], y_boundary_points_test[isx], net, radius)
    #print('Global solution:',u_global)



    #pde_loss = pde_loss_function(x_points_test, y_points_test, u_global_test[0:num_points_i_test,0], co_global_test[0:num_points_i_test,0])

    #boundary_loss = boundary_loss_function(x_boundary_points_test, y_boundary_points_test, u_global_test[num_points_i_test:num_points_test,0], co_global_test[num_points_i_test:num_points_test,0])

    #total_loss = pde_loss + boundary_loss
    
    #optimizer.zero_grad()
    #total_loss.backward(retain_graph=True)

    optimizer.step(compute_loss,x_points_test, y_points_test, u_global_test, co_global_test)

    
    total_loss = compute_loss(x_points_test, y_points_test, u_global_test, co_global_test)
    if epoch % 10 == 0:
        print('Epoch [%d], Loss: %.4f' % (epoch, total_loss.item()))
        #print('Epoch [%d], boundary_Loss: %.4f' % (epoch, boundary_loss.item()))
        #print('Epoch [%d], pde_Loss: %.4f' % (epoch, pde_loss.item()))
        
        record_loss = np.append(record_loss,total_loss.item())
        U = final_solution(x_test, y_test, net, radius,int(np.sqrt(num_points_i_test))).detach().numpy().reshape(int(np.sqrt(num_points_i_test)), int(np.sqrt(num_points_i_test)))
        print(np.mean(np.abs(U-U_analytic)))
        print(np.max(np.abs(U-U_analytic)))
        print(np.min(np.abs(U-U_analytic)))
        # Plot the approximate solution
        # plt.figure(int(epoch/10))
        # plt.contourf(X_vals, Y_vals, U, 50, cmap='viridis')
        # plt.colorbar()
        # plt.title('Approximate Solution')
        # plt.xlabel('x')
        # plt.ylabel('y')  

        # plt.draw()  # Update the figure
        # plt.pause(5)  # Wait for 0.1 seconds
        # plt.close()  # Clear the figure for the next plot
        
    if total_loss.item() < 0.1:
        flag = 0

    if abs(record_loss[-1] - record_loss[-2]) < 0.01:
        flag = 0

    epoch += 1


# Validation points
n_points = 20
x_vals = np.linspace(0, 1, n_points)
y_vals = np.linspace(0, 1, n_points)
X_vals, Y_vals = np.meshgrid(x_vals, y_vals)


# Convert to PyTorch tensors
#X_torch = torch.tensor(X_vals, dtype=torch.float32, requires_grad=True).view(-1, 1)
# print(X_torch.shape) # torch.Size([2500, 1]
#Y_torch = torch.tensor(Y_vals, dtype=torch.float32, requires_grad=True).view(-1, 1)

X_torch = torch.linspace(0, 1, n_points).view(-1, 1)
Y_torch = torch.linspace(0, 1, n_points).view(-1, 1)

U = final_solution(X_torch, Y_torch, net, radius,n_points).detach().numpy().reshape(n_points, n_points)


# Plot the approximate solution
plt.figure()
plt.contourf(X, Y, U, 50, cmap='viridis')
plt.colorbar()
plt.title('Approximate Solution')
plt.xlabel('x')
plt.ylabel('y')

# Plot the analytic solution
plt.figure()
plt.contourf(X, Y, U_analytic, 50, cmap='viridis')
plt.colorbar()
plt.title('Analytic Solution')
plt.xlabel('x')
plt.ylabel('y')

plt.show()




# def pde_loss_function(x_points, y_points, u_global):
#     batch_size = x_points.shape[0]
#     f = 2 * np.pi**2 * torch.sin(np.pi * x_points) * torch.sin(np.pi * y_points)

#     residuals = torch.zeros_like(u_global)

#     for i in range(batch_size):
#         u = u_global[i]
        
#         u_x = torch.autograd.grad(u, x_points[i], create_graph=True, retain_graph=True)[0]
#         u_y = torch.autograd.grad(u, y_points[i], create_graph=True, retain_graph=True)[0]
        
#         u_xx = torch.autograd.grad(u_x, x_points[i], create_graph=True, retain_graph=True)[0]
#         u_yy = torch.autograd.grad(u_y, y_points[i], create_graph=True, retain_graph=True)[0]
        
#         residuals[i] = u_xx + u_yy - f[i]

#     pde_loss = torch.mean(residuals ** 2)
#     return pde_loss

# # Generate random collocation points in the interior
# x_points = torch.rand(num_points_i, 1, requires_grad=True)
# y_points = torch.linspace(0,1,num_points_i, requires_grad=True)


# 修改global_solution函数，使其在每个点上使用独立的权重
# def global_solution(x, y, net, radius):
#     global_sol = 0
#     weights_sum = 0
#     for idx in range(num_points_i):
#         weight = unity_function(x, y, x_points[idx], y_points[idx], radius)
#         local_solution = net(x, y, idx)
#         weights_sum += weight
#         global_sol += weight * local_solution
#     for idx in range(4*num_points_b):
#         weight = unity_function(x, y, x_boundary_points[idx], y_boundary_points[idx], radius)
#         local_solution = net(x, y, idx + num_points_i)
#         weights_sum += weight
#         global_sol += weight * local_solution

#     return global_sol/weights_sum


#net = LocalFeatureModelWithWeights(num_features,num_points)

# 定义一个新的模型结构，其中权重是一个参数矩阵，每个取样点都有一个权重。
# class LocalFeatureModelWithWeights(nn.Module):
#     def __init__(self, num_features, num_points):
#         super(LocalFeatureModelWithWeights, self).__init__()
#         self.linear = nn.Linear(num_features, 1, bias=False)
#         self.weights = nn.Parameter(torch.ones(num_points, 1)) # 这里初始化为随机值，也可以选择其他方式

#     def forward(self, x, y, point_idx): # 通过point_idx选择对应的权重
#         features = torch.sin(np.pi * x) * torch.sin(np.pi * y)
#         u = self.linear(features)
#         return self.weights[point_idx] * u

#u = torch.matmul(features, self.local_weights.t()).squeeze(-1)  # [batch_size, 1]